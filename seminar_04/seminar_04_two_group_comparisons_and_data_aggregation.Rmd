Seminar 04 - Two group comparisons and data aggregation
========================================================

Preamble
--------

Load in the datasets:

```{r}
library(lattice)
library(ggplot2)
prDat <- read.table("../../../stat540/stat540_2014/examples/photoRec/data/GSE4051_data.tsv")
str(prDat, max.level = 0)
prDes <- readRDS("../../../stat540/stat540_2014/examples/photoRec/data/GSE4051_design.rds")
str(prDes)
```

Two sample tests -- one gene
----------------------------

Pick a single gene, somewhat randomly:

```{r}
set.seed(987)
(theGene <- sample(1:nrow(prDat), 1))
```

Make a new data frame, using the field descriptions, plus the gene expression values for the selected gene:

```{r}
pDat <- data.frame(prDes, gExp = unlist(prDat[theGene, ])) 
str(pDat)
```

Calculate the means for each genotype:

```{r}
aggregate(gExp ~ gType, pDat, FUN = mean)
```

A stripplot to sanity-test the t-test result:

```{r}
stripplot(gType ~ gExp, pDat)
```

Next, do a simple t-test:

```{r}
t.test(gExp ~ gType, pDat)
```

Then, save the object to inspect it:

```{r}
ttRes <- t.test(gExp ~ gType, pDat)
str(ttRes)
```

Extract some useful components:

```{r}
ttRes$statistic
ttRes$p.value
```

*Next: You try: draw a different gene at random or pick one for biological interest and look up the Affy probe ID. Use the t test, with and without the common variance assumption, the Wilcoxon, and/or the Kolmogorov-Smirnov test to assess differential expression. Can you pull test statistics and/or p-values from the different approaches into an common object, like a readable table? Are you getting the same message from the various approaches? Hint: wilcox.test(), ks.test().*

Pick a different gene randomly:

```{r}
set.seed(1124)
(theGene <- sample(1:nrow(prDat), 1))
```

Look up the Affy probe ID:

```{r}
row.names(prDat[theGene,])
```

Plots and means for sanity-checking:

```{r}
aggregate(gExp ~ gType, pDat, FUN = mean)
stripplot(gType ~ gExp, pDat)
(p <- ggplot(pDat) + geom_density(aes(x=gExp, colour=gType)))
```

Use the t test, with and without the common variance assumption:

```{r}
pDat <- data.frame(prDes, gExp = unlist(prDat[theGene, ])) 
(ttRes <- t.test(gExp ~ gType, pDat))
```

Without common variance assumption:

```{r}
(ttRes_equal_var <- t.test(gExp ~ gType, pDat, var.equal=TRUE))
```

Wilcoxon, Kolmogorov-Smirnov:

```{r}
(wilcoxRes <- wilcox.test(gExp ~ gType, pDat, exact = FALSE))
wt <- subset(pDat, gType == 'wt')
ko <- subset(pDat, gType == 'NrlKO')
(ksRes <- ks.test(wt$gExp, ko$gExp, exact = FALSE))
```

Pull test stats into a common object:

```{r}
(test_names <- c("t-test", "t-test, equal variance", "Wilcoxon", "Kolmogorov-Smirnov"))
(p_vals <- c(ttRes$p.value, ttRes_equal_var$p.value, wilcoxRes$p.value, ksRes$p.value))
df <- data.frame(test_names, p_vals)
```

*this is a start, but could probably be a little nicer*

Data Aggregation digression
---------------------------

### Install and load `plyr`, and the gapminder data set

```{r}
#install.packages("plyr", dependencies = TRUE)
library(plyr)
gdURL <- "http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt"
gDat <- read.delim(file = gdURL)
```

Check out the data frame:

```{r}
str(gDat)
summary(gDat)
```

### `ddply`

```{r}
(maxLeByCont <- ddply(gDat, ~ continent, summarize, maxLifeExp = max(lifeExp)))
str(maxLeByCont)
levels(maxLeByCont$continent)
```

I read this as "take the data frame `gDat`, split it up by continent, then summarize by getting the max life expectancy, and turn it back into a new data frame"

*You try: compute the minimum GDP per capita by continent. Here's what I get:*

```{r}
(minGDPeByCont <- ddply(gDat, ~ continent, summarize, minGDP = min(gdpPercap)))
```

Build the function inline:

```{r}
ddply(gDat, ~continent, summarize, nUniqCountries = length(unique(country)))
```

Without `summarize`:

```{r}
ddply(gDat, ~ continent,
      function(x) return(c(nUniqCountries = length(unique(x$country)))))
```

*Note: that looks like a Python lambda*

Multiple columns:

```{r}
ddply(gDat, ~ continent, summarize,
      minLifeExp = min(lifeExp), maxLifeExp = max(lifeExp),
      medGdpPercap = median(gdpPercap))
```

### Putting it all together: using `ddply()` and polishing the results

```{r}
jCountry <- "France"  # pick, but do not hard wire, an example
(jDat <- subset(gDat, country == jCountry))  # temporary measure!
```

Plot to check:

```{r}
xyplot(lifeExp ~ year, jDat, type = c("p", "r"))  # always plot the data
(p <- ggplot(jDat, aes(year, lifeExp)) + geom_point() + geom_smooth())
```

Fit a linear model:

```{r}
jFit <- lm(lifeExp ~ year, jDat)
summary(jFit)
```

Re-parameterize to start at 1952:

```{r}
(yearMin <- min(gDat$year))
jFit <- lm(lifeExp ~ I(year - yearMin), jDat)
summary(jFit)
```

Skip ahead to get the rest:

```{r}
jFun <- function(x) {
    estCoefs <- coef(lm(lifeExp ~ I(year - yearMin), x))
    names(estCoefs) <- c("intercept", "slope")
    return(estCoefs)
}
## jFun(subset(gDat, country == 'India')) to see what it does
jCoefs <- ddply(gDat, ~country, jFun)
```

Format as an HTML table:

```{r}
install.packages("xtable", dependencies = TRUE)
library(xtable)
set.seed(916)
foo <- jCoefs[sample(nrow(jCoefs), size = 15), ]
foo <- xtable(foo)
```

Print it out:

```{r results='asis'}
print(foo, type = "html", include.rownames = FALSE)
```

Back to the Data Aggregation Seminar
------------------------------------

### `apply()` for computing on rows and columns of matrices

Load back the `photoRec` data:

```{r}
kDat <- readRDS("../../../stat540/stat540_2014/examples/photoRec/data/GSE4051_MINI.rds")
kMat <- as.matrix(kDat[c('crabHammer', 'eggBomb', 'poisonFang')])
str(kMat)
```

Compute medians by hand and with `apply()`:

```{r}
median(kMat[ , 1]) # by column number
median(kMat[ , 'eggBomb']) # or by column name
```

With `apply()`:

```{r}
apply(kMat, 2, median) # input matrix, '2' for columns (1 is rows), function to apply
?apply
apply(kMat, 1, median)
```

Send extra arguments to a function:

```{r}
apply(kMat, 2, quantile, probs = 0.5)
apply(kMat, 2, quantile, probs = c(0.25, 0.75))
apply(kMat, 2, quantile, probs = c(0.25, 0.5, 0.75))
```

> Let's take the minimum gene expression for each sample, across these three genes. Then let's determine which gene contributed that maximum value.

*Should be 'minimum'*

```{r}
apply(kMat, 1, min)
colnames(kMat)[apply(kMat, 1, which.min)]
```

*New function here: `which.min`*

> Computing row- and column-wise sums and means is such an important special case that there are purpose-built and fast functions for this that I recommend you use when relevant.

```{r}
rowSums(kMat) #see also rowSums, colMeans, colSums
all.equal(rowSums(kMat), apply(kMat, 1, sum))
colMeans(kMat)
all.equal(colMeans(kMat), apply(kMat, 2, mean))
```

*Note: the above code is just showing that `rowSums` and `colMeans` give the same output as the `apply` results*

Compare `rowSums` and `apply` to a for loop:

```{r}
jRowSums <- rowSums(prDat)
jRowSums <- apply(prDat, 1, sum)
prMat <- as.matrix(prDat) # must have an actual matrix
jRowSums <- rep(NA, nrow(prDat)) # must initialize a receptacle
for(i in 1:nrow(prDat)) {
   jRowSums[i] <- sum(prMat[i, ])
}
```

### Computing on groups of observations with `aggregate()`

> More typical -- and conceptually trickier -- than the row- and column-wise operations above are operations on groups of observations, where the groups are induced by the levels of some factor (or combinations of multiple factors). We re-focus on data.frames, which is our go-to data receptacle.

> Let's compute on a quantitative variable, based on the levels of a factor using the built-in function aggregate(). Specifically, let's compute average expression of eggBomb for different levels of devStage.

```{r}
aggregate(eggBomb ~ devStage, kDat, FUN = mean)
```

> The call has familiar elements: a formula y ~ x reminiscent of other modelling and graphing calls, a data.frame where the variables are, and a function to apply. Read the documentation to learn more.

> We can split the data into groups based on a combination of factors.

```{r}
aggregate(eggBomb ~ gType * devStage, kDat, FUN = mean)
```

> We are not limited to computing a single value for each group. Although it's silly with such a small dataset, we can use range() to report the min and max.

```{r}
aggregate(eggBomb ~ gType * devStage, kDat, FUN = range)
```

### Two sample tests -- a handful of genes

> Let's grab the data from 6 genes. I've picked them for you: 3 are interesting ('hits'), 3 are not. I also reshape the data to be tall and skinny, which is generally a good policy and allows us to keep learning more about data aggregation.

```{r}
# Select six genes
keepGenes <- c("1431708_a_at", "1424336_at", "1454696_at",
               "1416119_at", "1432141_x_at", "1429226_at" )
# Subset the data for juse those genes from the larger dataset using %in%
# The data is 'short and wide' at this point
miniDat <- subset(prDat, rownames(prDat) %in% keepGenes)
# Re-shape the data frame to be long and skinny
miniDat <- data.frame(gExp = as.vector(t(as.matrix(miniDat))),
                      gene = factor(rep(rownames(miniDat), each = ncol(miniDat)),
                                    levels = keepGenes))
# Add the new miniDat onto the field descriptions data frame
miniDat <- suppressWarnings(data.frame(prDes, miniDat))
str(miniDat)
```

> Let's plot to make sure we have successfully gotten 3 clear 'hits' and 3 clear boring genes, as promised.

```{r}
stripplot(gType ~ gExp | gene, miniDat,
          scales = list(x = list(relation = "free")),
          group = gType, auto.key = TRUE)
```

> Smells "right": bottom row consists of 3 'hits', top row holds the boring genes.

> Let's use data aggregation techniques to conduct some two group comparisons for each of these 6 genes. Recall the syntax of the two-sample t-test for one gene:

```{r eval=FALSE}
t.test(gExp ~ gType, someDat)
```

> Conceptually, we want to make a sub-data.frame for each gene and provide in the place of someDat in a t test call like above. Sometimes that is a useful first step, when building up a data aggregation task. Walk before you run.

```{r}
someDat <- droplevels(subset(miniDat, gene == keepGenes[1]))
t.test(gExp ~ gType, someDat)
```

* Note: new function `droplevels`*

> How do we scale this up to all 6 genes? We have now outgrown the capability of `aggregate()`. If we restrict ourselves to the built-in functions, we'd need to look at functions like `tapply()`, `split()`, and `by()`. However I think it's the right time to start using plyr.

### The `plyr` package

