Seminar 06: Fitting and interpreting linear models (high volume)
================================================================

Runthrough of STAT540 [seminar06](http://www.ugrad.stat.ubc.ca/~stat540/seminars/seminar06_highVolumeLinearModelling.html)

Preliminaries
-------------

> If you haven't done so already, install limma 

```{r eval=FALSE}
source("http://www.bioconductor.org/biocLite.R")
biocLite("limma")
biocLite("statmod")
```

> Load the limma and/or lattice package, if you need to:

```{r}
library(limma)
library(lattice)
library(ggplot2)
library(knitr)
```

> Load the photoRec dataset:

```{r}
prDat <- read.table("../../../stat540/stat540_2014/examples/photoRec/data/GSE4051_data.tsv")
str(prDat, max.level = 0)
prDes <- readRDS("../../../stat540/stat540_2014/examples/photoRec/data/GSE4051_design.rds")
str(prDes)
```

> You might want to use the functions you wrote last week to extract and stripplot excerpts from the photoRec dataset. If you stored the code defining those functions cleanly in a script, you could make them available now by using the source() function.

I've got everything in an .Rmd document, so I'll add those functions back here:

```{r}
prepareData <- function(keepGenes){
  miniDat <- subset(prDat, rownames(prDat) %in% keepGenes)
  miniDat <- data.frame(gExp = as.vector(t(as.matrix(miniDat))),
                        gene = factor(rep(rownames(miniDat), 
                                      each = ncol(miniDat)),
                                       levels = keepGenes))
  miniDat <- suppressWarnings(data.frame(prDes, miniDat))
}
makeStripplot <- function(x, ...){
  stripplot(gExp ~ devStage | gene, x,
          group = gType, jitter.data = TRUE,
          auto.key = TRUE, type = c('p', 'a'), grid = TRUE, 
          ...)
}
makeggStripplot <- function(x){
  p <- ggplot(x, aes(factor(devStage), gExp, colour=gType, group=gType))
  p <- p + geom_point(size=5) + facet_wrap(~ gene, ncol=2)
  p <- p + stat_summary(fun.y = mean, geom="line")
  p <- p + scale_colour_brewer(palette='Dark2')
  p
}
```

The difficulty in estimating gene-wise variance
-----------------------------------------------

> The lmFit function from limma is arguably your main workhorse function for fitting a common linear model to the data for a very large number of genes. It has at least two strengths to recommend it:

> - It does this in a computationally efficient way, i.e. better than you writing a top-level for() loop and probably even better than pursuing an apply()-type strategy.
> - It borrows strength across the large number of genes (= datasets) to moderate the gene-wise estimate of error variance.

> Before we dive in and start using limma with the photoRec dataset, let's do a small simulation to illustrate how lousy variance estimates can be when the number of samples is small.

> Let's simulate data for 1000 genes. For each gene, we get 3 observations from a normal distribution with mean 0 and variance 1. We generate the data for each gene independent of the others.

```{r}
m <- 1000
n <- 3
x <- matrix(rnorm(m * n), nrow = m)
```

> Let's take the observed gene-wise variances. Yes, folks, we are estimating variance with samples of size 3. People do this all the time -- remember the video? We inspect them a bit numerically and graphically.

```{r}
obsVars <- apply(x, 1, var)
summary(obsVars)
mean(obsVars < 1/3)
densityplot(~obsVars, n = 200)
```

> Notice how many of the observed variances are freakishly small (and freakishly large!), even though they are indeed equal to 1 "on average". For example, we see that at least a quarter of the genes appear to exhibit a sample variance that is less than one-third the true variance. This can wreak havoc with statistical inference, such as t-statistics. This is what limma -- or the statistical methods it embodies, actually -- is designed to combat.

> Optional take-home exercise: Make the above simulation more realistic with two (or more) groups, different data-generating means and group differences, different data-generating gene-wise variances, etc.

Fit a linear model: explain gene expression in the wild type mice as a function of developmental stage (one-way ANOVA)
-----------------------------------

Let's just work with the wild type data.

```{r}
wtDes <- subset(prDes, gType == "wt")
str(wtDes)
```

```{r}
wtDat <- subset(prDat, select = prDes$gType == "wt")
str(wtDat, max.level = 0)
```

> Before we can use limma we must make our design matrix. Let's accept the default "ref + treatment effects" scheme for handling the devStage factor. I encourage you to inspect the design matrix and confirm it's what you expect.

```{r}
wtDesMat <- model.matrix(~devStage, wtDes)
str(wtDesMat)
```

```{r results='asis'}
kable(wtDesMat, format = "markdown")
```

... looks reasonable.

> Now we will fit the model, for all probes at once, and use eBayes() to moderate the estimated error variances:

```{r}
wtFit <- lmFit(wtDat, wtDesMat)
wtEbFit <- eBayes(wtFit)
```

> The first thing we might ask is "which genes show differential expression over the course of development"? This can be addressed with an overall F test for the model. In the language used in lecture, we will compare a "big" model to a "small" model, where the "big" model includes a mean parameter (or effect) for each level of devStage and the "small" model includes a single mean parameter, e.g. an intercept. You might expect this to be the F test performed by topTable() by default, i.e. when no specific coefficients or contrasts are given to the coef argument ...

```{r}
topTable(wtEbFit)
```

> You'll see that, by default, `topTable()` reports the top 10 hits. But let's take more care and specify explicitly the coefficients we want to test for equality with zero. Recall that one can specify these by number but I recommend doing this by name.

```{r eval=FALSE}
topTable(wtEbFit, coef = 2:5)  # cryptic! error-prone!
```

```{r}
colnames(coef(wtEbFit))  # remind yourself of the coef names
(dsHits <- topTable(wtEbFit, coef = grep("devStage", colnames(coef(wtEbFit)))))
```

> You will notice that these are not the same hits we got with our first call to topTable(). Compare, e.g., the Affy IDs for the top hits and/or look at the typical F statistic magnitudes. And so we learn that you really must use the coef argument (or a contrasts workflow in more complicated settings) to explicitly define what you regard as a hit.

> Use the hit list you stored above and your functions for extracting and plotting data to produce this plot for hits 3, 6, and 9 on the list.

```{r}
keepers <- c('1425222_x_at', '1422929_s_at', '1451617_at')
kDat  <- subset(prepareData(keepers), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

> Does it look plausible to you that -- using only wild type data -- these probes show the most compelling evidence for expression change over development? Note: I have redefined my data extraction and plotting functions to include only the wild type data. You can do that or not, as long as you can remember that all of today's models only work with wild type data.

> Optional exercise: use lm() on one or all 3 of these probes and check if the F stats and p-values are similar. Don't expect exact equality because you must remember that limma has moderated the estimated error variance.

```{r}
keepers <- c('1425222_x_at')
kDat  <- subset(prepareData(keepers), gType == 'wt')
mFit <- lm(formula = gExp ~ devStage, data = kDat)
summary(mFit)
```

From the `limma` model, the line of interest was:

`             X.Intercept. devStageP2 devStageP6 devStageP10 devStage4_weeks AveExpr        F      P.Value`

`1425222_x_at    0.88200    0.79950     1.54875         5.53175 7.02815 173.3572 4.348283e-14 4.340891e-10`

So, the estimates for the model parameters are similar, but the p-value and F-statistic are a bit different.

Be the boss of topTable()
-------------------------

> You need to learn to take control of topTable() by using various arguments to get the hits you want in the order you want. Furthermore, you should familiarize yourself with the output it returns, so you are comfortable extracting the output that you need.

> How many probes have Benjamini-Hochberg ("BH") adjusted p-values for the F test conducted above that are less than 1e-05?
> My answer: 350 probes.

Modify the earlier call and add in all the options to play around with:

```{r}
tTable <- topTable(wtEbFit, coef = grep("devStage", colnames(coef(wtEbFit))),
                   number=100000, genelist=wtEbFit$genes, adjust.method="BH",
                   sort.by="B", resort.by=NULL, p.value=1e-05, lfc=0, confint=FALSE)
```

This table now has `r nrow(tTable)` rows in it - matching the expected value.

> What is the 63rd hit on this list? Provide it's Affy ID, F statistic, BH adjusted p-value, and the estimated effect for developmental stage "P6" in that order. Here's what I get:

```{r}
row <- subset(tTable[63, ], select = c('F', 'adj.P.Val', 'devStageP6'))
row
```

> Consider the effects associated with developmental stages P2 and P10. Scatterplot the t statistics for the test that the P2 effect is zero against that for P10. Ideally this plot would be a high-volume scatterplot, include an x = y line, and have an aspect ratio of 1 and common axes, but just do your best. Here's what I get:

OK, make new topTables first for each test:

```{r}
P2Hits <- topTable(wtEbFit, coef = "devStageP2",
                   number=1000000, genelist=wtEbFit$genes, adjust.method="BH",
                   sort.by="none", resort.by=NULL, p.value=1, lfc=0, confint=FALSE)
P10Hits <- topTable(wtEbFit, coef = "devStageP10",
                   number=1000000, genelist=wtEbFit$genes, adjust.method="BH",
                   sort.by="none", resort.by=NULL, p.value=1, lfc=0, confint=FALSE)
```

Then plot the P2 t-statistic against the P10 t-statistic:

```{r}
p2_v_p10 <- data.frame(P2Hits$t, P10Hits$t)
str(p2_v_p10)
```

```{r}
p <- ggplot(p2_v_p10, aes(P2Hits.t, P10Hits.t))
p <- p + geom_point(alpha=0.3)
p <- p + geom_abline(slope=1)
p <- p + geom_density2d()
p
```

Try plotting a few different ways:

```{r}
p <- ggplot(tTable, aes(devStageP2, devStageP10))
p <- p + stat_bin2d()
p <- p + geom_abline(slope=1)
p
```

```{r}
p <- ggplot(tTable, aes(devStageP2, devStageP10))
p <- p + stat_binhex()
p <- p + geom_abline(slope=1)
p
```

> Create a densityplot of the associated adjusted p-values, so you can get a sense of which developmental stage, P2 or P10, is more clearly distinguished from baseline E16.

Put the adjusted p-values in a separate data framed, then `rbind` them:

```{r}
density_df_P2 <- data.frame(devStage = "P2", adj.P.Val = P2Hits$adj.P.Val)
density_df_P10 <- data.frame(devStage = "P10", adj.P.Val = P10Hits$adj.P.Val)
density_df <- rbind(density_df_P2, density_df_P10)
```

Now make density plots:

```{r}
p <- ggplot(density_df, aes(x=adj.P.Val, 
                            colour=devStage,
                            fill=devStage))
p <- p + geom_density(alpha=0.7)
p <- p + scale_colour_brewer(palette='Accent')
p <- p + scale_fill_brewer(palette='Accent')
p
```

> Is this what you'd expect?

Roughly, yes - more significant p-values on average for the difference between P10 and the start than P2 and the start.

> If you require a BH adjusted p-value less than 1e-03, how many hits do you get for P2? How many for P10? How much overlap is there?

First, get the significant hits for the desired p-value:

```{r}
p2_sig_hits <- topTable(wtEbFit, coef = "devStageP2",
                   number=nrow(wtEbFit), genelist=wtEbFit$genes, adjust.method="BH",
                   sort.by="none", resort.by=NULL, p.value=1e-03, lfc=0, confint=FALSE) 
p10_sig_hits <- topTable(wtEbFit, coef = "devStageP10",
                   number=nrow(wtEbFit), genelist=wtEbFit$genes, adjust.method="BH",
                   sort.by="none", resort.by=NULL, p.value=1e-03, lfc=0, confint=FALSE) 
```

Actually, I need the larger data frames so the values line up... 

```{r}
cutoff <- 1e-03
p2_v_p10 <- data.frame(P2 = P2Hits$adj.P.Val < cutoff,
                       P10 = P10Hits$adj.P.Val < cutoff)
head(p2_v_p10)
```

Then I can make a table:

```{r}
with(p2_v_p10, table(P2, P10))
```

*Note that the course version uses a new function, `addmargins`*:

Pretty-print:

```{r results='asis'}
tbl <- addmargins(with(p2_v_p10, table(P2, P10)))
kable(tbl, format = "markdown")
```

> Now just focus on the P10 effect. Create a scatterplot matrix of raw p-values, BH adjusted p-values, and BY p-values.

Get the raw and BH-adjusted p-values from the old data frame:

```{r}
str(P10Hits)
```

Calculate the BY-adjusted p-values:

```{r}
P10Hits_BY <- topTable(wtEbFit, coef = "devStageP10",
                   number=1000000, genelist=wtEbFit$genes, adjust.method="BY",
                   sort.by="none", resort.by=NULL, p.value=1, lfc=0, confint=FALSE)
```

Put them together in a data frame:

```{r}
p_value_cmp <- data.frame(raw = P10Hits$P.Value, 
                          BH = P10Hits$adj.P.Val,
                          BY = P10Hits_BY$adj.P.Val)
head(p_value_cmp)
summary(p_value_cmp)
```

Then do the pair-wise scatterplots:

```{r}
splom(p_value_cmp,
      panel = function(x, y, ... ) {
          panel.xyplot(x, y, pch = ".", ...)
          panel.abline(a = 0, b = 1, col = "orange")
      })
```

Try the ggplot version:

```{r}
p <- plotmatrix(p_value_cmp) + geom_smooth(method="lm")
p
```

... which suggests using `ggpairs` from `GGally`:

```{r}
library('GGally')
p <- ggpairs(p_value_cmp)
p
```

This takes a while and isn't really that nice.

> Is the relationship between raw and BH p-values what you expect? I'm not sure what to say about the BY p-values. I just wanted us to try at least one different method of p-value adjustment.

Yes - the BH-adjusted values are a bit more conservative overall.

Perform inference for some contrasts
------------------------------------

> Let's try to distinguish genes that have stable expression at the last three developmental stages (P6, P10, and 4_weeks) from those that do not. If expression doesn't change from P6 to P10 to 4_weeks, then the effects for all 3 of those developmental stages should be the same. That means that the difference between the P10 and P6 effects is zero and ditto for the difference between 4_weeks effect and P10 (or P6, for that matter). Let's form these contrasts.

```{r}
colnames(wtDesMat)
(cont.matrix <- makeContrasts(P10VsP6 = devStageP10 - devStageP6, 
                              fourweeksVsP10 = devStage4_weeks - devStageP10, 
                              levels = wtDesMat))
```

Fit a new model using the new contrast matrix:

```{r}
wtFitCont <- contrasts.fit(wtFit, cont.matrix)
wtEbFitCont <- eBayes(wtFitCont)
```

> What does `topTable()` do with our contrasts?

```{r}
topTable(wtEbFitCont)
```

> The top hits are probes where there is big change from P6 to P10, from P10 to 4_weeks, or both. Let's check that by plotting the data from the top 4 hits.

```{r}
keepers <- c('1440645_at', '1416041_at', '1425222_x_at', '1424852_at')
kDat  <- subset(prepareData(keepers), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

> So far, so good. These 4 probes show little expression change from P6 to P10 and a strong increase from P10 to 4_weeks. I would like to find some where there's a change in each case but perhaps in opposite direction. Let's press on.

> Let's use decideTests() to adjust the p-values for both contrasts globally, i.e. all together and then threshhold them at a cutoff of 1e-04.

```{r}
cutoff <- 1e-04
wtResCont <- decideTests(wtEbFitCont, p.value = cutoff, method = "global")
summary(wtResCont)
```

> We see there are 4 probes that go down from P6 to P10 and no hits going the other way. There are 8 probes that go down from P10 to 4_weeks and 46 going the other way. Let's try to pull out various hits and plot their data.

> Here are the 4 that decline from P6 to P10.

```{r}
(hits1 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] < 0)])
```

Plot these hits:

```{r}
kDat  <- subset(prepareData(hits1), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

> Here are 4 of the 8 that decline from P10 to 4_weeks.

*Note, I'm plotting all 8*

```{r}
(hits2 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] < 0)])
kDat  <- subset(prepareData(hits2), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

> Is there any overlap between these probes?

```{r}
intersect(hits1, hits2)
```

> Apparently not.

> Here are 4 of the 46 that increase from P10 to 4_weeks.

```{r}
(hits3 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] > 0)])
kDat  <- subset(prepareData(hits3[1:4]), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

> Is there any overlap between these probes and the previous "down" hits?

```{r}
intersect(hits1, hits3)
intersect(hits2, hits3)
```

> That's disappointing. If I revisit this workflow but make the p-value cutoff less stringent, maybe I can find the gene expression profile I'm looking for.

```{r}
cutoff <- 0.01
nHits <- 8
wtResCont <- decideTests(wtEbFitCont, p.value = cutoff, method = "global")
summary(wtResCont)
```

Then plot:

```{r}
hits1 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] < 0)]
kDat  <- subset(prepareData(hits1[1:nHits]), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

For the other effect of interest:

```{r}
hits2 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] < 0)]
kDat  <- subset(prepareData(hits2[1:nHits]), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

And the last one:

```{r}
hits3 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] > 0)]
kDat  <- subset(prepareData(hits3[1:nHits]), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

OK, one more:

```{r}
hits4 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] > 0)]
kDat  <- subset(prepareData(hits4[1:nHits]), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

Venn Diagram:

```{r}
vennDiagram(wtResCont)
```

Both effects at the same time:

```{r}
hits5 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] != 0 & wtResCont[, "fourweeksVsP10"] != 
    0)]
kDat  <- subset(prepareData(hits5), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

One more try:

*this is trying to find a gene where the P10vP6 is >0, and fourweeksvP10 is negative*

```{r}
hits6 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] > 0 & wtResCont[, "fourweeksVsP10"] < 
    0)]
kDat  <- subset(prepareData(hits6), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

> Take-home exercise: See if you can find one or more probes that have some expression changes up to P6 and then hold steady all the way to 4_weeks. Here's some I found.

OK, first, fit a new model with the desired contrasts:

```{r}
colnames(wtDesMat)
(cont.matrix <- makeContrasts(P6VsE16 = devStageP6 - Intercept, 
                              fourweeksVsP6 = devStage4_weeks - devStageP6, 
                              levels = wtDesMat))
```

Fit a new model using the new contrast matrix:

```{r}
wtFitCont <- contrasts.fit(wtFit, cont.matrix)
wtEbFitCont <- eBayes(wtFitCont)
topTable(wtEbFitCont)
```

Look at some of the top hits to sanity check:

```{r}
keepers <- c('1438657_x_at', '1423641_s_at', '1438940_x_at', '1454613_at')
kDat  <- subset(prepareData(keepers), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

Use decideTests to adjust all the p-values, with a not-so-stringent p cutoff:

```{r}
cutoff <- 0.01
wtResCont <- decideTests(wtEbFitCont, p.value = cutoff, method = "global")
summary(wtResCont)
```

Looks like a lot of hits, so I'll us a more stringent p-value cutoff...

```{r}
cutoff <- 1e-07
wtResCont <- decideTests(wtEbFitCont, p.value = cutoff, method = "global")
summary(wtResCont)
```

OK, let's find some genes...

```{r}
hits <- rownames(prDat)[which(wtResCont[, "P6VsE16"] < 0 & wtResCont[, "fourweeksVsP6"] == 
    0)]
kDat  <- subset(prepareData(hits[1:6]), gType == 'wt')
makeStripplot(kDat)
makeggStripplot(kDat)
```

My version might have been too complicated - it looks like I didn't need to re-fit the whole model. Also, I'm not sure I've got the best hits here. Here's the version from the course notes:

```{r}
(cont.matrix <- makeContrasts(P10VsP6 = devStageP10 - devStageP6, 
                              fourweeksVsP10 = devStage4_weeks - devStageP10, 
                              levels = wtDesMat))
wtFitCont <- contrasts.fit(wtFit, cont.matrix)
wtEbFitCont <- eBayes(wtFitCont)

lateStuff <- topTable(wtEbFitCont, n = Inf, sort = "none")
earlyStuff <- topTable(wtEbFit,
                       coef = grep("devStageP[26]", colnames(coef(wtEbFit))),
                       n = Inf, sort = "none")
pVals <-
  data.frame(earlyStuff = earlyStuff$adj.P.Val,
             lateStuff = lateStuff$adj.P.Val)
xyplot(lateStuff ~ earlyStuff, pVals)
discHits <- with(pVals,
     which(earlyStuff < quantile(earlyStuff, probs = 0.05) &
             lateStuff > quantile(lateStuff, probs = 0.95)))
length(discHits)
```

